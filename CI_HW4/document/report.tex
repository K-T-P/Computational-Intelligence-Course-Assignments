\documentclass[12pt]{article}
\usepackage[top=3cm, bottom=2.5cm, left=2cm, right=2.5cm]{geometry}
\usepackage{listings}
\usepackage{float}
\usepackage{subfig}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{ptext}
\usepackage{amsmath}
\usepackage[usenames,dvipsnames]{color,xcolor}
\usepackage{xepersian}
\setlatintextfont[Scale=1]{Times New Roman}
\settextfont[Scale=1]{XB Niloofar}


\title{تمرین سری چهارم درس هوش محاسباتی}
\author{کورش تقی پور پاسدار 
\lr{400521207}}
\makeglossary
\begin{document}
	\maketitle
	\tableofcontents
	\newpage
	\section{سوال اول} 
	فرمول کلی تعیین وزن‌ها بصورت زیر می‌باشد.
	\begin{equation}
		W_{ij} = \sum^{P}_{k=1} x^{k}_{i}x^{k}_{j}
	\end{equation}
	در ابتدا مقادیر وزن‌ها را بصورت زیر تعیین می‌کنیم.
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\toprule
		\lr{neuron 8} & \lr{neuron 7} & \lr{neuron 6} & \lr{neuron 5} & \lr{neuron 4} & \lr{neuron 3} & \lr{neuron 2} & \lr{neuron 1} & \lr{}\\
		\midrule
		\lr{-1} & \lr{3} & \lr{-1} & \lr{1} & \lr{3} & \lr{-1} & \lr{1} & \lr{0} & \lr{neuron 1} \\
		\midrule
		\lr{1} & \lr{1} & \lr{1} & \lr{-1} & \lr{1} & \lr{1} & \lr{0} & \lr{1} & \lr{neuron 2}\\
		\midrule
		\lr{3} & \lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{0} & \lr{1} & \lr{-1} & \lr{neuron 3}\\
		\midrule
		\lr{-1} & \lr{3} & \lr{-1} & \lr{1} & \lr{0} & \lr{-1} & \lr{1} & \lr{3} & \lr{neuron 4}\\
		\midrule
		\lr{1} & \lr{1} & \lr{-3} & \lr{0} & \lr{1} & \lr{1} & \lr{-1} & \lr{1} & \lr{neuron 5}\\
		\midrule
		\lr{-1} & \lr{-1} & \lr{0} & \lr{-3} & \lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{neuron 6}\\
		\midrule
		\lr{-1} & \lr{0} & \lr{-1} & \lr{1} & \lr{3} & \lr{-1} & \lr{1} & \lr{3} & \lr{neuron 7}\\
		\midrule
		\lr{0} & \lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{3} & \lr{1} & \lr{-1} & \lr{neuron 8}\\
		\bottomrule
	\end{tabular}
\end{table}
\subsection{\lr{a}}
طبق نتایج بدست آمده در بخش دوم،‌ می‌توان گفت الگوی اول و سوم برای شبکه هاپفیلد پایدار است ولی الگوی دوم پایدار نیست زیرا به مقدار متفاوتی همگرا شده است.
\subsection{\lr{b}}
داده اول را طبق زیر حساب می‌کنیم.
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\toprule
		\lr{8} & \lr{7} & \lr{6} & \lr{5} & \lr{4} & \lr{3} & \lr{2} & \lr{1} & \lr{}\\
		\midrule
		\lr{1} & \lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{1} & \lr{input(0)}\\
		\midrule
		\lr{1} & \lr{1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{-1} & \lr{step 1} \\
		\midrule
		\lr{1} & \lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{-1} & \lr{step 2}\\
		\midrule
		\lr{1} & \lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{-1} & \lr{step 3}\\
		\bottomrule
	\end{tabular}
\end{table}
همانطور که مشاهده می‌شود، برای داده اول، به مقدار درست همگرا می‌شود.
\newline
داده دوم را طبق زیر حساب می‌کنیم.
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\toprule
		\lr{8} & \lr{7} & \lr{6} & \lr{5} & \lr{4} & \lr{3} & \lr{2} & \lr{1} & \lr{}\\
		\midrule
		\lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{-1} & \lr{-1} & \lr{1} & \lr{1} & \lr{input(1)}\\
		\midrule
		\lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{step 1}\\
		\midrule
		\lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{step 2}\\
		\midrule
		\lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{-1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{step 3}\\
		\bottomrule
	\end{tabular}
\end{table}
همانطور که مشاهده می‌شود، برای داده دوم (که ۲ بیت خطا داشت)، درنهایت به مقداری همگرا شد که با مقدار اصلی، ۱ بیت اختلاف دارد. 
حال برای داده سوم انجام می‌دهیم.
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\toprule
		\lr{8} & \lr{7} & \lr{6} & \lr{5} & \lr{4} & \lr{3} & \lr{2} & \lr{1} & \lr{}\\
		\midrule
		\lr{1} & \lr{-1} & \lr{1} & \lr{1} & \lr{-1} & \lr{1} & \lr{1} & \lr{1} & \lr{input(3)}\\
		\midrule
		\lr{1} & \lr{-1} & \lr{1} & \lr{1} & \lr{-1} & \lr{1} & \lr{1} & \lr{-1} & \lr{step 1}\\
		\midrule
		\lr{1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{-1} & \lr{1} & \lr{1} & \lr{-1} & \lr{step 2}\\
		\midrule
		\lr{1} & \lr{-1} & \lr{1} & \lr{-1} & \lr{-1} & \lr{1} & \lr{1} & \lr{-1} & \lr{step 3}\\
		\bottomrule
	\end{tabular}
\end{table}
همانطور که مشاهده می‌شود، داده سوم به طور کامل به مقدار اصلی خود همگرا شد.
\section{سوال ۲}
در شبکه هاپفیلد، هر نورون تنها یکی از دو حالت \lr{1} و \lr{-1} را می‌تواند داشته باشد. پس تعداد کلی حالات برابر با \lr{2} به توان تعداد نورون‌ها می‌باشد. از طرفی تابع انرژی طوری طراحی شده است که در هر آپدیت، یا کاهش می‌یابد یا ثابت می‌ماند. چون تعداد کلی حالات محدود است، پس این کاهش یافتن تا بینهایت نمی‌تواند انجام شود و سرانجام در یک مینیمم محلی متوقف خواهد شد.
\newline
در آپدیت وزن‌ها بصورت \lr{asynchronous}، میزان تغییر انرژی بصورت زیر خواهد بود.
\begin{equation}
	\Delta E = \frac{-1}{2}\sum(W_{ij} \times \Delta S_{i} \times S_{j})
\end{equation}
حال تغییر مقدار $S_{i}$ به دو صورت است. 
\begin{enumerate}
	\item از \lr{-1} به \lr{1} که در اینصورت  $\sum_{j} W_{ij}S_{j} \ge 0 $
	\item از \lr{1} به \lr{-1} که در اینصورت $\sum_{j} W_{ij}S_{j} \le 0 $
\end{enumerate}
حال در دو حالت داریم:
\begin{eqnarray*}
	1- \Delta S_{i} &=& 1 - (-1) = 2,\quad\sum_{j}W_{ij}S_{j} \ge 0\\
		\Delta E  &=& \frac{-1}{2}\sum(W_{ij} \times \Delta S_{i} \times S_{j}) \le 0\\
	2- \Delta S_{i} &=& -1 -(+1) = -2,\quad\sum_{j}W_{ij}S_{j} \le 0\\
		\Delta E &=& \frac{-1}{2} \sum(W_{ij}\times \Delta S_{i} \times S_{j}) \le 0
\end{eqnarray*}
بنابراین در هر دو حالت، انرژی شبکه یا ثابت مانده یا کاهش می‌یابد.
\section{سوال ۳}
شبکه هاپقیلد توانایی محدودی در یادگیری ارقام دارد و تنها ورودی‌هایی که به داده‌های آموزشی نزدیک هست را می‌تواند به خوبی تشخیص دهد و درصورت وجود فاصله قابل توجه، به مشکل برمی‌خورد. در شبکه کوهونن نیز توانایی متوسطی در تشخیص ارقام دارد. شبکه \lr{MLP} توانایی بالایی در رده‌بندی \LTRfootnote{\lr{Classification}} دارد ولی نیاز به داده آموزشی زیادی دارد.
\newline
شبکه هاپفیلد با ذخیره‌سازی داده‌ها، سعی می‌کند ورودی‌ها را به این داده‌های ذخیره شده نزدیک کند و به اینصورت مقدار رقم را تشخیص می‌دهد. اشکال شبکه هاپفیلد، عدم توانایی تشخیص ارقامی است که با داده‌های آموزشی تفاوت پیکسلی زیادی دارند (با وجود اینکه مقدار آنها یکی است). شبکه کوهونن با نقشه توپولوژی سعی در رده‌بندی داده‌ها دارد. شبکه \lr{MLP} با آموزش دیدن برروی بخش زیادی از داده‌های ورودی، ارقام را یاد می‌گیرد. شبکه \lr{MLP} توانایی بیشتری در تعمیم‌دهی (و در نتیجه تشخیص گستره \LTRfootnote{Range} بیشتری از داده‌ها) دارد ولی نیازمند داده آموزشی زیاد می‌باشد.
\newline
درمورد تفاوت روش‌های آموزشی، شبکه هاپفیلد با استفاده از قانون \lr{Hebbian}، شبکه کوهونن با استفاده از رقابت برنده و \lr{MLP} با استفاده از \lr{Back Propagation} به آموزش وزن‌های خود می‌پردازند. درمورد قابلیت ذخیره و بازیابی الگو، شبکه هاپفیلد قابلیت ذخیره و بازیابی بالایی دارد، به این معنی که برای ذخیره داده‌های داده شده (در زمان آموزش) و سپس بازیابی آنها با استفاده از بخشی از داده کاربرد زیادی دارد. شبکه کوهونن قبلیت متوسط و شبکه \lr{MLP} قابلیت پایینی دارد زیرا شبکه \lr{MLP} بجای حفظ کردن داده‌ها به یادگیری الگوهای مشترک و کلی بین آنها می‌پردازد و هدف نیز یادگیری الگوهای مشترک است (و نه حفظ کردن داده‌ها). درمورد توانایی تعمیم، شبکه هاپفیلد توانایی ضعیفی دارد زیرا این شبکه برای ذخیره و بازیابی داده‌های مشخصی (بجای تعمیم‌دهی کلی) طراحی شده است. شبکه کوهونن دارای توانایی متوسط و شبکه \lr{MLP} دارای توانایی بالایی است زیرا هدف اصلی این شبکه، یادگیری الگوی مشترک میان داده‌ها و بدست آوردن توانایی تعمیم‌دهی است. از نظر کارایی محاسباتی، شبکه‌های هاپفیلد، کوهونن و \lr{MLP} کارایی محاسباتی بالا، متوسط و پایینی دارند به این معنی که نیازمندی محاسبات آنها متفاوت است. از نقاط قوت شبکه هاپفیلد می‌توان به سادگی آموزش وزن‌ها و محاسبات اشاره کرد و از نقاط ضعف آن هم به محدودیت در تعداد داده‌های قابل آموزش (نسبت به تعداد نورون‌ها) و تعمیم‌دهی ضعیف اشاره کرد. از نقاط قوت شبکه کوهونن می‌توان به خودسازماندهی و نقشه‌های توپولوژیکی اشاره و از نقاط صعف هم می‌توان حساسیت به ترتیب داده‌ها را نام برد. از نقاط قوت شبکه \lr{MLP} می‌توان به قابلیت تعمیم‌دهی و توانایی یادگیری بالا با افزایش تعداد نورون‌ها (نسبت به شبکه هاپفیلد) و از نقاط ضعف هم می‌توان به نیازمندی به تعداد داده زیاد و پیچیدگی محاسباتی نام برد.
\section{سوال ۴}
نوت‌بوک مربوطه تکمیل شده است.
\end{document}