{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part A: Adaline Implementation"
      ],
      "metadata": {
        "id": "3wsdKNcpafMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "8Pghds5UaXra"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Adaline:\n",
        "    def __init__(self, in_features=2, lr=0.01, stop_tolerance=1e-1): # DON'T CHANGE THIS METHOD\n",
        "        \"\"\"\n",
        "        Initialize the Adaline model.\n",
        "\n",
        "        Parameters:\n",
        "        - in_features (int): Number of input features (default is 2).\n",
        "        - lr (float): Learning rate for weight updates (default is 0.01).\n",
        "        - stop_tolerance (float): Tolerance for stopping criterion (default is 1e-1).\n",
        "        \"\"\"\n",
        "        np.random.seed(42)\n",
        "        self.lr = lr\n",
        "        self.stop_tolerance = stop_tolerance\n",
        "        self.in_features = in_features\n",
        "        self.b = np.random.random()\n",
        "        self.weight = np.random.random(in_features)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Compute the net input for the given input features.\n",
        "\n",
        "        Parameters:\n",
        "        - X (numpy.ndarray): Input features.\n",
        "\n",
        "        Returns:\n",
        "        - net (numpy.ndarray): The computed net input.\n",
        "        \"\"\"\n",
        "        # TODO: Implement the forward pass to compute the net input\n",
        "        # Hint: Use the dot product of X and weights and add the bias.\n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "    def step(self, X, net, y):\n",
        "        \"\"\"\n",
        "        Update weights and bias based on the error.\n",
        "\n",
        "        Parameters:\n",
        "        - X (numpy.ndarray): Input feature vector.\n",
        "        - net (float): Computed net input.\n",
        "        - y (float): Actual target value.\n",
        "\n",
        "        Returns:\n",
        "        - float: The largest weight change to monitor convergence.\n",
        "        \"\"\"\n",
        "        # TODO: Update weights and bias based on the error\n",
        "        # Hint: Use the Adaline learning rule. Calculate delta_w and delta_b.\n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "    def train(self, X, Y, max_epochs=10):\n",
        "        \"\"\"\n",
        "        Train the Adaline model using the provided data.\n",
        "\n",
        "        Parameters:\n",
        "        - X (numpy.ndarray): Input features for training.\n",
        "        - Y (numpy.ndarray): Target labels for training.\n",
        "        - max_epochs (int): Maximum number of training epochs (default is 10).\n",
        "        \"\"\"\n",
        "        # TODO: Train the model until the stopping condition or max_epochs\n",
        "        # Hint: Loop through epochs and update weights for each sample.\n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "    def activation_function(self, X):\n",
        "        \"\"\"\n",
        "        Apply the activation function (step function) to the net input.\n",
        "\n",
        "        Parameters:\n",
        "        - X (numpy.ndarray): Net input values.\n",
        "\n",
        "        Returns:\n",
        "        - numpy.ndarray: Activated output values.\n",
        "        \"\"\"\n",
        "        # TODO: Implement the activation function (step function)\n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict class labels for new input data.\n",
        "\n",
        "        Parameters:\n",
        "        - X (numpy.ndarray): Input features for prediction.\n",
        "\n",
        "        Returns:\n",
        "        - numpy.ndarray: Predicted class labels.\n",
        "        \"\"\"\n",
        "        # TODO: Predict class labels for new inputs\n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "    def accuracy(self, X, y):\n",
        "        \"\"\"\n",
        "        Calculate the accuracy of the predictions.\n",
        "\n",
        "        Parameters:\n",
        "        - X (numpy.ndarray): Input features for prediction.\n",
        "        - y (numpy.ndarray): Actual target labels.\n",
        "\n",
        "        Returns:\n",
        "        - float: The accuracy of the model.\n",
        "        \"\"\"\n",
        "        # TODO: Compute the accuracy of the predictions\n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "    def plot_scatter(self, X, Y): # DON'T CHANGE THIS METHOD\n",
        "        \"\"\"\n",
        "        Plot the scatter of input features and the decision boundary.\n",
        "\n",
        "        Parameters:\n",
        "        - X (numpy.ndarray): Input features.\n",
        "        - Y (numpy.ndarray): Target labels.\n",
        "        \"\"\"\n",
        "        plt.scatter(\n",
        "            X[:, 0],\n",
        "            X[:, 1],\n",
        "            c=Y,\n",
        "            cmap='tab20b',\n",
        "            edgecolors=\"k\",\n",
        "            alpha=0.95,\n",
        "        )\n",
        "        h = 0.01\n",
        "        xx, yy = np.meshgrid(np.arange(min(X[:, 0]) - 2, max(X[:, 0]), h) + 1,\n",
        "                             np.arange(min(X[:, 1]) - 1, max(X[:, 1]), h) + 1)\n",
        "        Z = self.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "        Z = Z.reshape(xx.shape)\n",
        "        cm = plt.cm.tab20b\n",
        "        plt.contourf(xx, yy, Z, cmap=cm, alpha=0.5)\n",
        "        plt.title(\"Adaline Decision Boundary\")\n",
        "        plt.xlabel(\"x\")\n",
        "        plt.ylabel(\"y\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "S50JWOeuba8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DON'T CHANGE THIS CELL\n",
        "\n",
        "# Main code to load data, train, and visualize\n",
        "def main():\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv('/content/Madaline.csv', names=['x', 'y', 'label'], header=None)\n",
        "    # Shuffle the dataset\n",
        "    df = df.sample(frac=1)\n",
        "\n",
        "    # Prepare inputs and targets\n",
        "    data = df[['x', 'y']].to_numpy()\n",
        "    target = df[['label']].to_numpy()\n",
        "\n",
        "    # Convert labels to bipolar\n",
        "    target[np.isclose(target, 0)] = -1\n",
        "\n",
        "    # Create and train the Adaline model\n",
        "    adaline = Adaline(in_features=2, lr=0.01, stop_tolerance=1e-1)\n",
        "\n",
        "    # Flatten target for training\n",
        "    adaline.train(data, target.flatten(), max_epochs=100)\n",
        "\n",
        "    # Predict and calculate accuracy\n",
        "    predictions = adaline.predict(data)\n",
        "    accuracy = adaline.accuracy(data, target.flatten())\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    # Plot the results\n",
        "    adaline.plot_scatter(data, target.flatten())\n",
        "\n",
        "    # Create confusion matrix and classification report\n",
        "    cm = confusion_matrix(target, predictions)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"g\")\n",
        "    plt.xlabel(\"Predicted labels\")\n",
        "    plt.ylabel(\"True labels\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"confusion_matrix.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "    print(classification_report(target, predictions))"
      ],
      "metadata": {
        "id": "_bxeirBoabP3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DON'T CHANGE THIS CELL\n",
        "# Execute main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "2AgOKHL0adTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B: Madaline Implementation"
      ],
      "metadata": {
        "id": "gPdOh4FaanoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Madaline Network is considered to have 2 hidden layers for this class implementation\n",
        "class MadalineClassifier:\n",
        "    def __init__(self, csv_file, num_neurons_layer1=3, num_neurons_layer2=2, learning_rate=0.0001, max_iter=200):\n",
        "        \"\"\"\n",
        "        Initialize the Madaline classifier.\n",
        "\n",
        "        Parameters:\n",
        "        - csv_file (str): Path to the CSV file containing the dataset.\n",
        "        - num_neurons_layer1 (int): Number of neurons in the first layer (default is 3).\n",
        "        - num_neurons_layer2 (int): Number of neurons in the second layer (default is 2).\n",
        "        - learning_rate (float): Learning rate for weight updates (default is 0.0001).\n",
        "        - max_iter (int): Maximum number of iterations for training (default is 200).\n",
        "        \"\"\"\n",
        "        # DON'T CHANGE THIS METHOD\n",
        "        self.df = pd.read_csv(csv_file, names=['x', 'y', 'label'], header=None)\n",
        "        self.df = self.df.sample(frac=1)\n",
        "        self.inputs = self.df[['x', 'y']].to_numpy()\n",
        "        self.target = self.df[['label']].to_numpy()\n",
        "        self.target[np.isclose(self.target, 0)] = -1\n",
        "        self.num_neurons_layer1 = num_neurons_layer1\n",
        "        self.num_neurons_layer2 = num_neurons_layer2\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_iter = max_iter\n",
        "        self.weights = None\n",
        "        self.biases = None\n",
        "        self.weights_layer2 = None\n",
        "        self.biases_layer2 = None\n",
        "\n",
        "    def plot_data(self): # DON'T CHANGE THIS METHOD\n",
        "        \"\"\"\n",
        "        Plot the input data points in a scatter plot.\n",
        "\n",
        "        The method visualizes the dataset by plotting the two classes with different colors.\n",
        "        \"\"\"\n",
        "        df0 = self.df.loc[self.df['label'] == 0]\n",
        "        df1 = self.df.loc[self.df['label'] == 1]\n",
        "\n",
        "        plt.scatter(df0['x'], df0['y'], c=\"red\", linewidths=2)\n",
        "        plt.scatter(df1['x'], df1['y'], c=\"blue\", linewidths=2)\n",
        "\n",
        "        plt.xlabel(\"x\")\n",
        "        plt.ylabel(\"y\")\n",
        "        plt.legend([\"Class 1\", \"Class 2\"])\n",
        "        plt.grid(True)\n",
        "        plt.title(\"Scatter Plot\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"scatter_plot.pdf\")\n",
        "        plt.show()\n",
        "\n",
        "    def initialize_weights(self, sm):\n",
        "        \"\"\"\n",
        "        Initialize weights and biases for the Madaline model.\n",
        "\n",
        "        Parameters:\n",
        "        - sm (int): Size of the input data.\n",
        "\n",
        "        This method initializes weights for the first and second layers, as well as biases.\n",
        "        \"\"\"\n",
        "        # ToDo: Implement the weight initialization method.\n",
        "        # Hints:\n",
        "        # 1. Initialize weights for the first layer.\n",
        "        # 2. Initialize biases for the first layer.\n",
        "        # 3. Initialize weights and biases for the second layer.\n",
        "\n",
        "        pass\n",
        "\n",
        "    def find_decision_boundary(self, start_x, end_x, weights, biases):\n",
        "        \"\"\"\n",
        "        Calculate the decision boundary based on weights and biases.\n",
        "\n",
        "        Parameters:\n",
        "        - start_x (float): Starting x-value for the decision boundary.\n",
        "        - end_x (float): Ending x-value for the decision boundary.\n",
        "        - weights (numpy.ndarray): Weights for the layer.\n",
        "        - biases (numpy.ndarray): Biases for the layer.\n",
        "\n",
        "        Returns:\n",
        "        - (numpy.ndarray, numpy.ndarray): x-coordinates and corresponding y-coordinates of the decision boundary.\n",
        "        \"\"\"\n",
        "        # ToDo: Implement the decision boundary calculation.\n",
        "        # Hints: You might calculate the output of the decision boundary\n",
        "        # using the weights and biases.\n",
        "\n",
        "        pass\n",
        "\n",
        "    def apply_activation_function(self, net):\n",
        "        \"\"\"\n",
        "        Apply the activation function to the net input.\n",
        "\n",
        "        Parameters:\n",
        "        - net (numpy.ndarray): Net input values.\n",
        "\n",
        "        Returns:\n",
        "        - numpy.ndarray: Activated output values.\n",
        "        \"\"\"\n",
        "        # ToDo: Implement the activation function. (Step Function)\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward_propagation(self, weights, inputs, biases, should_reshape):\n",
        "        \"\"\"\n",
        "        Perform forward propagation through the network.\n",
        "\n",
        "        Parameters:\n",
        "        - weights (numpy.ndarray): Weights for the layer.\n",
        "        - inputs (numpy.ndarray): Input data.\n",
        "        - biases (numpy.ndarray): Biases for the layer.\n",
        "        - should_reshape (bool): Indicates if inputs should be reshaped.\n",
        "\n",
        "        Returns:\n",
        "        - (numpy.ndarray, numpy.ndarray): Net input and activated output.\n",
        "        \"\"\"\n",
        "        # ToDo: Implement forward propagation.\n",
        "        # Hints:\n",
        "        # 1. If should_reshape is True, reshape it to the correct shape.\n",
        "        # 2. Calculate net_input\n",
        "        pass\n",
        "\n",
        "    def update_weights(self, inputs, target, net_input, output):\n",
        "        \"\"\"\n",
        "        Update the weights based on the target and output.\n",
        "\n",
        "        Parameters:\n",
        "        - inputs (numpy.ndarray): Input feature vector.\n",
        "        - target (float): Actual target value.\n",
        "        - net_input (float): Computed net input.\n",
        "        - output (float): Activated output.\n",
        "\n",
        "        Updates the weights and biases for the neurons based on the error.\n",
        "        \"\"\"\n",
        "        # ToDo: Implement the weight update logic.\n",
        "        pass\n",
        "\n",
        "    def calculate_error(self, target, output):\n",
        "        \"\"\"\n",
        "        Calculate the error based on the target and predicted output.\n",
        "\n",
        "        Parameters:\n",
        "        - target (numpy.ndarray): Actual target values.\n",
        "        - output (numpy.ndarray): Predicted output values.\n",
        "\n",
        "        Returns:\n",
        "        - float: Calculated mean squared error.\n",
        "        \"\"\"\n",
        "        # ToDo: Implement the error calculation.\n",
        "        pass\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"\n",
        "        Predict class labels for the given input data.\n",
        "\n",
        "        Parameters:\n",
        "        - inputs (numpy.ndarray): Input data for prediction.\n",
        "\n",
        "        Returns:\n",
        "        - numpy.ndarray: Predicted class labels.\n",
        "        \"\"\"\n",
        "        # ToDo: Implement the prediction function.\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Train the Madaline model on the input data.\n",
        "\n",
        "        This method implements the training loop for the Madaline model.\n",
        "        \"\"\"\n",
        "        # ToDo: Implement the training loop.\n",
        "        # Hints:\n",
        "        # 1. Shuffle the dataset and reset the index.\n",
        "        # 2. Initialize necessary variables.\n",
        "        # 3. You might want to perform forward & backward prop.\n",
        "        pass\n",
        "\n",
        "    def plot_error(self, error_list, df0, df1): # DON'T CHANGE THIS METHOD\n",
        "        \"\"\"\n",
        "        Plot the training error and decision boundaries.\n",
        "\n",
        "        Parameters:\n",
        "        - error_list (list): List of mean squared error values for each epoch.\n",
        "        - df0 (DataFrame): DataFrame containing class 0 data.\n",
        "        - df1 (DataFrame): DataFrame containing class 1 data.\n",
        "        \"\"\"\n",
        "        plt.plot(error_list)\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Mean Squared Error')\n",
        "        plt.title('Error Plot')\n",
        "        plt.grid(True)\n",
        "        plt.savefig('error_plot.pdf')\n",
        "        plt.show()\n",
        "\n",
        "        plt.scatter(df0['x'], df0['y'], c=\"red\", linewidths=0.1)\n",
        "        plt.scatter(df1['x'], df1['y'], c=\"blue\", linewidths=0.1)\n",
        "\n",
        "        for i in range(self.num_neurons_layer1):\n",
        "            px1, px2 = self.find_decision_boundary(-2, 2, self.weights[i], self.biases[i])\n",
        "            plt.plot(px1, px2)\n",
        "\n",
        "        plt.xlabel(\"x\")\n",
        "        plt.ylabel(\"y\")\n",
        "        plt.legend([\"Class 1\", \"Class 2\"])\n",
        "        plt.xlim([-2, 2])\n",
        "        plt.ylim([-2, 2])\n",
        "        plt.savefig('error_plot1.pdf')\n",
        "        plt.show()\n",
        "\n",
        "        predicted_output = self.predict(self.inputs)\n",
        "        cm = confusion_matrix(self.target, predicted_output)\n",
        "\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"g\")\n",
        "        plt.xlabel(\"Predicted labels\")\n",
        "        plt.ylabel(\"True labels\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"confusion_matrix.pdf\")\n",
        "        plt.show()\n",
        "\n",
        "        print(classification_report(self.target, predicted_output))"
      ],
      "metadata": {
        "id": "S0__QgiNcV3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DON'T CHANGE THIS CELL\n",
        "# Usage\n",
        "classifier = MadalineClassifier('/content/Madaline.csv', num_neurons_layer1=3, num_neurons_layer2=2, max_iter=200)\n",
        "classifier.plot_data()\n",
        "weights, biases, error_list = classifier.train()"
      ],
      "metadata": {
        "id": "QcUycRszaw32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DON'T CHANGE THIS CELL\n",
        "# Usage\n",
        "classifier = MadalineClassifier('/content/Madaline.csv', num_neurons_layer1=5, num_neurons_layer2=2, max_iter=200)\n",
        "classifier.plot_data()\n",
        "weights, biases, error_list = classifier.train()"
      ],
      "metadata": {
        "id": "yKJ6iWJvbIvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DON'T CHANGE THIS CELL\n",
        "# Usage\n",
        "classifier = MadalineClassifier('/content/Madaline.csv', num_neurons_layer1=10, num_neurons_layer2=2, max_iter=200)\n",
        "classifier.plot_data()\n",
        "weights, biases, error_list = classifier.train()"
      ],
      "metadata": {
        "id": "NrSrbYqJa16m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}